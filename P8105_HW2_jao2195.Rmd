---
title: "P8105_HW2_jao2195"
output: github_document
---
## Homework 2 


################################################################################
### Problem 0
This “problem” focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files.

To that end:

-create a public GitHub repo + local R Project; we suggest naming this repo / directory -p8105_hw2_YOURUNI (e.g. p8105_hw2_ajg2202 for Jeff), but that’s not required

-create a single .Rmd file named p8105_hw2_YOURUNI.Rmd that renders to github_document

-create a subdirectory to store the local data files, and use relative paths to access these data files

-submit a link to your repo via Courseworks

-Your solutions to Problems 1 (not graded), 2, and 3 should be implemented in your .Rmd file, and your git commit history should reflect the process you used to solve these Problems.

For this Problem, we will assess adherence to the instructions above regarding repo structure, git commit history, and whether we are able to knit your .Rmd to ensure that your work is reproducible. Adherence to appropriate styling and clarity of code will be assessed in Problems 1+ (only 2 and 3 will be graded).

################################################################################
### Problem 1
This problem uses the FiveThirtyEight data; these data were gathered to create the interactive graphic on this page. In particular, we’ll use the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is to merge these into a single data frame using year and month as keys across datasets.

First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r}

#Loading in Packages 
library(readxl)
library(moderndive)
library(ggplot2)
library(tidyverse)
library(readr)
library(lubridate)
library(magrittr)
library(dplyr)

pols_month =read_csv("pols-month.csv")
#View(pols_month)

## Checking the prez_gop column to determine who is Republican (1) or Not (0)

##Checking/Making sure values of of 0 and 1.
unique(pols_month$prez_gop)

## Noticed that all the values are not 0s and 1s. Some are 2s.....
prez2<- pols_month%>%
  filter(prez_gop== 2)
#View(prez2)
# ^^ Looking/Googling at the 2s and the year to see who was US president during that year.
# It was a Republican (checked online) so changing 2s to 1s.

pols_month2 =read_csv("pols-month.csv") %>% 
             janitor::clean_names() %>%    #Cleaning data
             separate(mon,into = c("year", "month", "day")) %>%
             mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
             mutate(month = month.name[month]) %>%
             mutate(prez_gop = replace(prez_gop, prez_gop==2, 1 )) %>% #changing 2s to 1s per above
             mutate(president = ifelse(prez_gop == '1', 'GOP', 'DEM'))%>% 
             select(-day, -prez_gop, -prez_dem)

#head(pols_month2)
#View(pols_month2)
#unique(pols_month2$prez_gop)

```

Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r}
snp = read_csv("snp.csv") |> 
  separate(date, into= c("month", "day", "year")) |>
  mutate(year = as.numeric(year)) |>
  mutate(year = if_else(year <= 15, year + 2000, year)) |>
  mutate(year = if_else(year >= 15, year + 1900, year)) |>
  select(year, month, close) 

#class(snp$year)
#unique(snp$year)
#View(snp)
#left_join(x = _, y = month_df) %>% 
```


Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r}
unemployment = read_csv("unemployment.csv")

unemployment = unemployment %>% 
  rename(year = Year) %>% 
  pivot_longer(Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment" ) %>% 
  select(year, month_abb, unemployment)

#View(unemployment)
```

Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r}
# final_data = 
#   left_join(pols_month2, snp)

#str(final_data)
#View(final_data)
```


Note: we could have used a date variable as a key instead of creating year and month keys; doing so would help with some kinds of plotting, and be a more accurate representation of the data. Date formats are tricky, though. For more information check out the lubridate package in the tidyverse.


#############################################################################
### Problem 2
This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website.

1) Read and clean the Mr. Trash Wheel sheet
2) Specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel 
use reasonable variable names
3) Omit rows that do not include dumpster-specific data

### [Dataset A] Mister Trashwheel Cleaning Process
```{r}
#Reading/Cleaning/and Creating ID Variable for the sheet Mister Trash Wheel Data
mrtrashwheel<- read_excel("202309 Trash Wheel Collection Data.xlsx", 
                sheet = 1,                   # Specifying Sheet in Excel File
                skip = 1,                    # Using Skip argument to skip first header with image in sheet
                 ) %>% 
               janitor::clean_names() %>%    # Cleaning the data
               mutate(SHEET_ID = "MISTER") %>%   # Creating new ID column to identify this sheet
               select(-x15, -x16)  %>%     # Omitting random blank columns X15 and X16 in dataset
               select(SHEET_ID, everything()) %>%  # Moving the Sheet ID to the beginning/ front of the dataset
          
               mutate(year = as.numeric(year)) %>%  #changing from character to numeric/double to merge
               mutate(dumpster = as.numeric(dumpster)) %>% 
               mutate(year = as.numeric(year)) %>% 
               mutate(date = as.character(date)) %>% 
               mutate(weight_tons = as.numeric(weight_tons)) %>% 
               mutate(volume_cubic_yards = as.numeric(volume_cubic_yards)) %>% 
              mutate(plastic_bottles = as.numeric(plastic_bottles)) %>% 
              mutate(polystyrene = as.numeric(polystyrene)) %>% 
              mutate(cigarette_butts= as.numeric(cigarette_butts)) %>% 
              mutate(plastic_bags= as.numeric(plastic_bags)) %>% 
              mutate(wrappers= as.numeric(wrappers)) %>% 
               mutate(homes_powered= as.numeric(homes_powered))

# Dropping rows that do not have dumpster specific data
nrow(mrtrashwheel)
mrtrashwheel <- mrtrashwheel[-585,]

#View(mrtrashwheel)

  
#Viewing Mister Trash Wheel Data 
#View(mrtrashwheel)
#month = month[as.numeric(month)] 
#class(mrtrashwheel)
```

4) The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.
```{r}

#Overwriting the existing mrtrashwheel "homes_powered" column with the correct calculations. 
mrtrashwheel = mrtrashwheel %>%  
                    mutate(homes_powered =(weight_tons*500)/30)

# Checking out the change the the dataset.
# View(mrtrashwheel)
```


5) Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to all datasets before combining.

### [Dataset B] Professor Trashwheel Cleaning Process
```{r}

proftrashwheel<- read_excel("202309 Trash Wheel Collection Data.xlsx", 
                sheet = 2,                   # Specifying Sheet in Excel File
                skip = 1,                    # Using Skip argument to skip first header with image in sheet
                 ) %>% 
               janitor::clean_names() %>%    # Cleaning the data
               mutate(SHEET_ID = "PROFESSOR") %>%   # Creating new ID column to identify this sheet
               select(SHEET_ID, everything()) %>% # Moving the Sheet ID to the beginning/ front of the dataset
          
               mutate(sports_balls ="NONE") %>% #Adding sportsball column for merge later; Does not contain sportballs column
               relocate(sports_balls, .before = homes_powered) %>% 
               mutate(sports_balls = as.numeric(sports_balls)) %>% 
               mutate(dumpster = as.numeric(dumpster)) %>% 
               mutate(year = as.numeric(year)) %>% 
               mutate(date = as.character(date)) %>% 
               mutate(weight_tons = as.numeric(weight_tons)) %>% 
                mutate(volume_cubic_yards = as.numeric(volume_cubic_yards)) %>% 
              mutate(plastic_bottles = as.numeric(plastic_bottles)) %>% 
                 mutate(polystyrene = as.numeric(polystyrene)) %>% 
                mutate(cigarette_butts= as.numeric(cigarette_butts)) %>% 
                mutate(plastic_bags= as.numeric(plastic_bags)) %>% 
                mutate(wrappers= as.numeric(wrappers)) %>% 
                 mutate(homes_powered= as.numeric(homes_powered))
  
# Dropping rows that do not have dumpster specific data
nrow(proftrashwheel)
proftrashwheel <- proftrashwheel [-107,]

#View(proftrashwheel )
#Viewing ProfessorTrash Wheel Data 
# View(proftrashwheel)
# class(proftrashwheel)

```

### [Dataset C] Gwynnda Trashwheel Cleaning Process
```{r, warning=FALSE}

gwynndatrashwheel <- read_excel("202309 Trash Wheel Collection Data.xlsx", 
                sheet = 4,                   # Specifying Sheet in Excel File
                skip = 1,                    # Using Skip argument to skip first header with image in sheet
                 ) %>% 
               janitor::clean_names() %>%    # Cleaning the data
               mutate(SHEET_ID = "GWYNNDA") %>%   # Creating new ID column to identify this sheet
               select(SHEET_ID, everything()) %>%  # Moving the Sheet ID to the beginning/ front of the dataset
               # Dropping rows that do not have dumpster specific data
               mutate(sports_balls ="NONE") %>% #Adding sportsball column for merge later; Does not contain sportballs column
               mutate(glass_bottles ="NONE") %>% 
               relocate(sports_balls, .before = homes_powered) %>% 
               relocate(glass_bottles, .before = plastic_bags) %>% 
               mutate(sports_balls = as.numeric(sports_balls)) %>% 
               mutate(glass_bottles = as.numeric(glass_bottles)) %>% 
               mutate(dumpster = as.numeric(dumpster)) %>% 
               mutate(year = as.numeric(year)) %>% 
               mutate(date = as.character(date)) %>% 
               mutate(weight_tons = as.numeric(weight_tons)) %>% 
               mutate(volume_cubic_yards = as.numeric(volume_cubic_yards)) %>%  
               mutate(plastic_bottles = as.numeric(plastic_bottles)) %>% 
               mutate(polystyrene = as.numeric(polystyrene)) %>% 
              mutate(cigarette_butts= as.numeric(cigarette_butts)) %>% 
              mutate(plastic_bags= as.numeric(plastic_bags)) %>% 
              mutate(wrappers= as.numeric(wrappers)) %>% 
              mutate(homes_powered= as.numeric(homes_powered)) 

#nrow(gwynndatrashwheel)
 gwynndatrashwheel <- gwynndatrashwheel[-156,]
 gwynndatrashwheel <- gwynndatrashwheel[-157,]
  
#nrow(gwynndatrashwheel)
#Viewing Gwynnda Trash Wheel Data 
#View(gwynndatrashwheel)

```

### [Final Dataset] Merging of Three (3) Trashwheel Datasets (MISTER, PROFFESSOR, & GWYNNDA)
```{r}

#Combining all sheets! :)
all_three_trashwheels =
 bind_rows(mrtrashwheel,proftrashwheel, gwynndatrashwheel) 

#View(all_three_trashwheels)
# Filtering for Gywnnda
gwnn_jul21<- all_three_trashwheels %>%
  subset(SHEET_ID == "GWYNNDA") %>% 
  subset(month== "July") %>% 
  subset(year== "2021") 

#View(gwnn_jul21)
```


### Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in July of 2021?

The number of observations in the merged datset is  `r nrow(all_three_trashwheels)`.
The key variables in out dataset  are `r colnames(all_three_trashwheels[1:15])`.
The total weight of trash collected by Professor Trashwheel was `r sum(all_three_trashwheels$weight_tons)`.
The total number of cigarette butts by Gwynnda in July of 2021 was `r sum(gwnn_jul21$cigarette_butts)`. 

################################################################################
### Problem 3
This problem uses data collected in an observational study to understand the trajectory of Alzheimer’s disease (AD) biomarkers. Study participants were free of Mild Cognitive Impairment (MCI), a stage between the expected cognitive decline of normal aging and the more serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The study monitored the development of MCI and recorded the age of MCI onset during the follow-up period, with the last visit marking the end of follow-up. APOE4 is a variant of the apolipoprotein E gene, significantly associated with a higher risk of developing Alzheimer’s disease. The amyloid β
42/40 ratio holds significant promise for diagnosing and predicting disease outcomes. This ratio undergoes changes over time and has been linked to the manifestation of clinical symptoms of Alzheimer’s disease.

Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). Discuss important steps in the import process and relevant features of the dataset. How many participants were recruited, and of these how many develop MCI? What is the average baseline age? What proportion of women in the study are APOE4 carriers?

  ################################################################################
### Problem 3
This problem uses data collected in an observational study to understand the trajectory of Alzheimer’s disease (AD) biomarkers. Study participants were free of Mild Cognitive Impairment (MCI), a stage between the expected cognitive decline of normal aging and the more serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The study monitored the development of MCI and recorded the age of MCI onset during the follow-up period, with the last visit marking the end of follow-up. APOE4 is a variant of the apolipoprotein E gene, significantly associated with a higher risk of developing Alzheimer’s disease. The amyloid β
42/40 ratio holds significant promise for diagnosing and predicting disease outcomes. This ratio undergoes changes over time and has been linked to the manifestation of clinical symptoms of Alzheimer’s disease.

Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). Discuss important steps in the import process and relevant features of the dataset. How many participants were recruited, and of these how many develop MCI? What is the average baseline age? What proportion of women in the study are APOE4 carriers?
  
```{r}
#### Importing, Cleaning, and Organizing MCI baseline data
# Sex and APOE4 recoded

baseline_mci = read_csv("MCI_baseline.csv", #importing
               skip=1) %>% 
               janitor::clean_names() %>% #cleaning
               mutate (sex = ifelse(sex == 1, "MALE", "FEMALE"), #making columns not numeric
              apoe4 = ifelse(apoe4 == 1, "GENE PRESENT", "GENE NOT PRESENT") ) %>% #making columns not numeric
               mutate(age_at_onset= as.numeric(age_at_onset)) #coercing NAs, numeric for calculations

#those who met baseline criteria
baseline_mci_criteria = baseline_mci %>% filter(age_at_onset!= "NA")

#women with APOE4 gene
women_in_dataset =  baseline_mci_criteria %>% filter(sex=="FEMALE")
women_APOE4_carr = baseline_mci_criteria %>% filter(sex=="FEMALE") %>% filter(apoe4 == "GENE PRESENT")

#proprtion of women in the dataset with the APOe4 gene
prop_APOE4_carr= nrow(women_APOE4_carr)/nrow(women_in_dataset)

#nrow(baseline_mci)
#View(baseline_mci)
#Important steps in the import process is to skip a row to retrive the data properly. 
#Relavant fetures of the dataset include the gender, presence or absence of gene, age at onset, education, and current ages. There were 483 participants recruited. 

```
#Comments on Dataset baseline
There was a total of `r nrow(baseline_mci)` participants recruited. 
There were `r nrow(baseline_mci_criteria)` participants who developed MCI.
The average baseline age for the participants who developed MCI was `r mean(baseline_mci_criteria$age_at_onset)`.
The proportion of women in the study that were APOE4 carriers was `r prop_APOE4_carr`.


Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values; 
comment on the steps on the import process and the features of the dataset.

```{r}
amyloid_mci<- read_csv("mci_amyloid.csv", #importing data, skipping first text row that is not headers
          skip=1) %>% 
            janitor::clean_names() %>% #cleaning data headers
            rename(id=study_id) %>% #renaming id col to match baseline dataset
             mutate(time_2= as.numeric(time_2)) %>% 
            mutate(time_4= as.numeric(time_4)) %>% 
            mutate(time_6= as.numeric(time_6)) %>% 
            mutate(time_8= as.numeric(time_8)) %>% 
            mutate(baseline = as.numeric(baseline))
#View(amyloid_mci)

```

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

#Comments on Dataset amyloid
There was a total of `r nrow(amyloid_mci)` participants recruited. 
The average amyloid at Time 2 was `r mean(amyloid_mci$time_2)`.
The average amyloid at Time 4 was `r mean(amyloid_mci$time_2)`.
The average amyloid at Time 6 was `r mean(amyloid_mci$time_2)`.
The average amyloid at Time 8 was `r mean(amyloid_mci$time_2)`.

```{r}
# write.csv(MCI_df, file = "results/mci.csv")
```

###############################
####   End Of Homework 2   ####
###############################
